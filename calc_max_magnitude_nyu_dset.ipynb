{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop over all the NYU data and calculate the maximim magnitude for later reference for normalization. While we are here, store other metadata aswell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in NYU dataset: 92\n",
      "Processing file 1 of 92\n",
      "Processing file 2 of 92\n",
      "Processing file 3 of 92\n",
      "Processing file 4 of 92\n",
      "Processing file 5 of 92\n",
      "Processing file 6 of 92\n",
      "Processing file 7 of 92\n",
      "Processing file 8 of 92\n",
      "Processing file 9 of 92\n",
      "Processing file 10 of 92\n",
      "Processing file 11 of 92\n",
      "Processing file 12 of 92\n",
      "Processing file 13 of 92\n",
      "Processing file 14 of 92\n",
      "Processing file 15 of 92\n",
      "Processing file 16 of 92\n",
      "Processing file 17 of 92\n",
      "Processing file 18 of 92\n",
      "Processing file 19 of 92\n",
      "Processing file 20 of 92\n",
      "Processing file 21 of 92\n",
      "Processing file 22 of 92\n",
      "Processing file 23 of 92\n",
      "Processing file 24 of 92\n",
      "Processing file 25 of 92\n",
      "Processing file 26 of 92\n",
      "Processing file 27 of 92\n",
      "Processing file 28 of 92\n",
      "Processing file 29 of 92\n",
      "Processing file 30 of 92\n",
      "Processing file 31 of 92\n",
      "Processing file 32 of 92\n",
      "Processing file 33 of 92\n",
      "Processing file 34 of 92\n",
      "Processing file 35 of 92\n",
      "Processing file 36 of 92\n",
      "Processing file 37 of 92\n",
      "Processing file 38 of 92\n",
      "Processing file 39 of 92\n",
      "Processing file 40 of 92\n",
      "Processing file 41 of 92\n",
      "Processing file 42 of 92\n",
      "Processing file 43 of 92\n",
      "Processing file 44 of 92\n",
      "Processing file 45 of 92\n",
      "Skipped file 45 due to error: [Errno 5] Can't read data (file read failed: time = Mon Sep 25 12:29:52 2023\n",
      ", filename = '/mnt/c/Users/qvloh/Documents/phd_lok/datasets/prostate_ksp_nyu/validation_T2_1/file_prostate_AXT2_0008.h5', file descriptor = 67, errno = 5, error message = 'Input/output error', buf = 0x7f6d2d9bb490, total read size = 4034792320, bytes this sub-read = 4034792320, bytes actually read = 18446744073709551615, offset = 0)\n",
      "Processing file 46 of 92\n",
      "Processing file 47 of 92\n",
      "Processing file 48 of 92\n",
      "Processing file 49 of 92\n",
      "Processing file 50 of 92\n",
      "Processing file 51 of 92\n",
      "Processing file 52 of 92\n",
      "Processing file 53 of 92\n",
      "Processing file 54 of 92\n",
      "Processing file 55 of 92\n",
      "Processing file 56 of 92\n",
      "Processing file 57 of 92\n",
      "Processing file 58 of 92\n",
      "Processing file 59 of 92\n",
      "Processing file 60 of 92\n",
      "Processing file 61 of 92\n",
      "Processing file 62 of 92\n",
      "Processing file 63 of 92\n",
      "Processing file 64 of 92\n",
      "Skipped file 64 due to error: [Errno 5] Can't read data (file read failed: time = Mon Sep 25 12:39:58 2023\n",
      ", filename = '/mnt/c/Users/qvloh/Documents/phd_lok/datasets/prostate_ksp_nyu/validation_T2_1/file_prostate_AXT2_0117.h5', file descriptor = 68, errno = 5, error message = 'Input/output error', buf = 0x7f6d573bc100, total read size = 3890626320, bytes this sub-read = 3890626320, bytes actually read = 18446744073709551615, offset = 0)\n",
      "Processing file 65 of 92\n",
      "Processing file 66 of 92\n",
      "Skipped file 66 due to error: [Errno 5] Can't read data (file read failed: time = Mon Sep 25 12:41:02 2023\n",
      ", filename = '/mnt/c/Users/qvloh/Documents/phd_lok/datasets/prostate_ksp_nyu/validation_T2_1/file_prostate_AXT2_0124.h5', file descriptor = 68, errno = 5, error message = 'Input/output error', buf = 0x7f6d03a35ec8, total read size = 859607368, bytes this sub-read = 859607368, bytes actually read = 18446744073709551615, offset = 0)\n",
      "Processing file 67 of 92\n",
      "Processing file 68 of 92\n",
      "Processing file 69 of 92\n",
      "Processing file 70 of 92\n",
      "Processing file 71 of 92\n",
      "Processing file 72 of 92\n",
      "Processing file 73 of 92\n",
      "Skipped file 73 due to error: [Errno 5] Can't read data (file read failed: time = Mon Sep 25 12:45:10 2023\n",
      ", filename = '/mnt/c/Users/qvloh/Documents/phd_lok/datasets/prostate_ksp_nyu/validation_T2_1/file_prostate_AXT2_0173.h5', file descriptor = 67, errno = 5, error message = 'Input/output error', buf = 0x7f6e254ddc88, total read size = 433333128, bytes this sub-read = 433333128, bytes actually read = 18446744073709551615, offset = 0)\n",
      "Processing file 74 of 92\n",
      "Processing file 75 of 92\n",
      "Processing file 76 of 92\n",
      "Processing file 77 of 92\n",
      "Skipped file 77 due to error: [Errno 5] Can't read data (file read failed: time = Mon Sep 25 12:47:28 2023\n",
      ", filename = '/mnt/c/Users/qvloh/Documents/phd_lok/datasets/prostate_ksp_nyu/validation_T2_1/file_prostate_AXT2_0195.h5', file descriptor = 67, errno = 5, error message = 'Input/output error', buf = 0x7f6e2b7db768, total read size = 329533608, bytes this sub-read = 329533608, bytes actually read = 18446744073709551615, offset = 0)\n",
      "Processing file 78 of 92\n",
      "Processing file 79 of 92\n",
      "Processing file 80 of 92\n",
      "Processing file 81 of 92\n",
      "Processing file 82 of 92\n",
      "Processing file 83 of 92\n",
      "Processing file 84 of 92\n",
      "Processing file 85 of 92\n",
      "Processing file 86 of 92\n",
      "Processing file 87 of 92\n",
      "Processing file 88 of 92\n",
      "Processing file 89 of 92\n",
      "Processing file 90 of 92\n",
      "Processing file 91 of 92\n",
      "Processing file 92 of 92\n"
     ]
    }
   ],
   "source": [
    "def read_h5_attributes(hf):\n",
    "    attrs = {}\n",
    "    for k, v in hf.attrs.items():\n",
    "        attrs[k] = v\n",
    "    return attrs\n",
    "\n",
    "\n",
    "def calculate_magnitude_references(ksp):\n",
    "    max_magni_ref = np.max(np.abs(ksp))\n",
    "    min_magni_ref = np.min(np.abs(ksp))\n",
    "    return max_magni_ref, min_magni_ref\n",
    "\n",
    "\n",
    "def extract_magnitude_references_from_files(files, output_path):\n",
    "    for idx, fpath in enumerate(files):\n",
    "        print(f\"Processing file {idx+1} of {len(files)}\")\n",
    "        \n",
    "        try:\n",
    "            hf = h5py.File(fpath, 'r')\n",
    "            ksp = hf['kspace'][()]\n",
    "            shape = ksp.shape\n",
    "            attrs = read_h5_attributes(hf)\n",
    "            max_magni_ref, min_magni_ref = calculate_magnitude_references(ksp)\n",
    "\n",
    "            data_dict = {\n",
    "                'max_magni_ref': max_magni_ref,\n",
    "                'min_magni_ref': min_magni_ref,\n",
    "                'fpath': fpath,\n",
    "                'shape': shape\n",
    "            }\n",
    "            data_dict.update(attrs)\n",
    "\n",
    "            df = pd.DataFrame([data_dict])\n",
    "            df.to_csv(output_path, mode='a', header=(idx == 0), sep=';', index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipped file {idx+1} due to error: {e}\")\n",
    "\n",
    "\n",
    "nyu_root = Path('/mnt/c/Users/qvloh/Documents/phd_lok/datasets/prostate_ksp_nyu')\n",
    "nyu_files_h5 = glob.glob(str(nyu_root) + '/*/file_prostate_AXT2_*.h5')\n",
    "output_csv_path = nyu_root / 'max_magni_ref.csv'\n",
    "\n",
    "print(f\"Number of files in NYU dataset: {len(nyu_files_h5)}\")\n",
    "\n",
    "# Don't delete current csv but add a timestamp to it\n",
    "# if output_csv_path.exists():\n",
    "#     output_csv_path.rename(output_csv_path.with_suffix(f\".{datetime.now().strftime('%Y%m%d-%H%M%S')}.csv\"))\n",
    "\n",
    "\n",
    "extract_magnitude_references_from_files(nyu_files_h5, output_csv_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "direct_ml_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
